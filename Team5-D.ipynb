{"cells":[{"cell_type":"markdown","source":["Krantas Konstantinos, 9975  \n","Strikos Konstantinos, 9517"],"metadata":{"id":"8kNmIM9Oc0S1"}},{"cell_type":"markdown","metadata":{"id":"mfBb9zjWIhHC"},"source":["# **Question 4 - NN Testing**"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"u0tjh0tTEELa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704479155787,"user_tz":-120,"elapsed":10654,"user":{"displayName":"Konstantinos Strikos","userId":"00806009806564184535"}},"outputId":"c940d234-67bf-4ae6-9efe-c0600c121c26"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_15 (Dense)            (None, 32)                12832     \n","                                                                 \n"," dropout_5 (Dropout)         (None, 32)                0         \n","                                                                 \n"," dense_16 (Dense)            (None, 16)                528       \n","                                                                 \n"," dense_17 (Dense)            (None, 5)                 85        \n","                                                                 \n","=================================================================\n","Total params: 13445 (52.52 KB)\n","Trainable params: 13445 (52.52 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/20\n","88/88 [==============================] - 2s 11ms/step - loss: 2.7746 - accuracy: 0.4044 - val_loss: 2.1238 - val_accuracy: 0.6071\n","Epoch 2/20\n","88/88 [==============================] - 1s 9ms/step - loss: 1.7315 - accuracy: 0.6913 - val_loss: 1.3744 - val_accuracy: 0.7543\n","Epoch 3/20\n","88/88 [==============================] - 1s 9ms/step - loss: 1.1298 - accuracy: 0.8092 - val_loss: 1.0037 - val_accuracy: 0.8043\n","Epoch 4/20\n","88/88 [==============================] - 1s 9ms/step - loss: 0.8251 - accuracy: 0.8628 - val_loss: 0.8325 - val_accuracy: 0.8286\n","Epoch 5/20\n","88/88 [==============================] - 1s 9ms/step - loss: 0.6549 - accuracy: 0.8864 - val_loss: 0.7515 - val_accuracy: 0.8314\n","Epoch 6/20\n","88/88 [==============================] - 1s 13ms/step - loss: 0.5442 - accuracy: 0.9121 - val_loss: 0.7093 - val_accuracy: 0.8386\n","Epoch 7/20\n","88/88 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.9150 - val_loss: 0.7100 - val_accuracy: 0.8129\n","Epoch 8/20\n","88/88 [==============================] - 2s 19ms/step - loss: 0.4192 - accuracy: 0.9296 - val_loss: 0.6917 - val_accuracy: 0.8186\n","Epoch 9/20\n","88/88 [==============================] - 1s 9ms/step - loss: 0.3908 - accuracy: 0.9271 - val_loss: 0.6785 - val_accuracy: 0.8429\n","Epoch 10/20\n","88/88 [==============================] - 0s 3ms/step - loss: 0.3684 - accuracy: 0.9393 - val_loss: 0.7165 - val_accuracy: 0.8243\n","Epoch 11/20\n","88/88 [==============================] - 0s 2ms/step - loss: 0.3438 - accuracy: 0.9489 - val_loss: 0.7311 - val_accuracy: 0.8257\n","Epoch 12/20\n","88/88 [==============================] - 0s 3ms/step - loss: 0.3305 - accuracy: 0.9450 - val_loss: 0.7071 - val_accuracy: 0.8200\n","32/32 [==============================] - 0s 1ms/step\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","from mlxtend.plotting import plot_decision_regions\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import StandardScaler\n","from keras.models import Sequential, load_model\n","from keras.layers import Dense, Dropout\n","from keras.regularizers import l2\n","from keras.optimizers import RMSprop\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","df = pd.read_csv('datasetC.csv')\n","X = df.iloc[:, :-1].values\n","y = df.iloc[:, -1].values - 1  # Subtract 1 to make the range [0, 4]\n","\n","# Manage feature values\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Create the MLP model\n","model = Sequential()\n","model.add(Dense(units=32, activation='relu', input_dim=X_train.shape[1], kernel_regularizer=l2(0.03)))\n","model.add(Dropout(0.2))\n","model.add(Dense(units=16, activation='relu'))\n","model.add(Dense(units=5, activation='softmax'))\n","\n","# Verification\n","model.compile(optimizer=RMSprop(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","model.summary()\n","\n","# Implement EarlyStopping and ModelCheckpoint\n","early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","model_checkpoint = ModelCheckpoint('best_model', monitor='val_loss', save_best_only=True)\n","history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.20, shuffle=True,\n","                    callbacks=[early_stopping, model_checkpoint])\n","\n","test_data = pd.read_csv('datasetCTest.csv')\n","X_test = scaler.transform(test_data.values)\n","\n","# Predictions using the best model saved by ModelCheckpoint\n","best_model = load_model('best_model')\n","predictions = best_model.predict(X_test)\n","\n","# Create the numpy array\n","labels5 = np.argmax(predictions, axis=1) + 1  # Add 1 to revert back to the original range [1, 5]\n","np.save('labels5.npy', labels5)"]},{"cell_type":"markdown","source":["# Classifiers used with worse accuracy"],"metadata":{"id":"A_eCeo_YqdZB"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"JduB4ZqU53lX"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from xgboost import XGBClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import accuracy_score\n","from sklearn.ensemble import RandomForestClassifier\n","\n","# Manage feature values\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","X = df.iloc[:, :-1].values\n","y = df.iloc[:, -1].values - 1  # Subtract 1 to make the range [0, 4]\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Train the Decision Tree Classifier\n","dt = DecisionTreeClassifier(random_state=42)\n","dt.fit(X_train, y_train)\n","\n","# Predictions on validation data\n","pred_dt = dt.predict(X_val)\n","\n","# Calculate accuracy\n","accuracy_dt = accuracy_score(y_val, pred_dt)\n","print(f\"Decision Tree Classifier Accuracy: {accuracy_dt}\")\n","\n","# Train the XGBoost Classifier\n","xgb = XGBClassifier(n_estimators=400, eta=0.6, random_state=42, max_depth=3)\n","xgb.fit(X_train, y_train)\n","\n","# Predictions on validation data\n","pred_xgb = xgb.predict(X_val)\n","\n","# Calculate accuracy\n","accuracy_xgb = accuracy_score(y_val, pred_xgb)\n","print(f\"XGBoost Classifier Accuracy: {accuracy_xgb}\")\n","\n","# Train the Random Forest Classifier\n","rf = RandomForestClassifier(random_state=42)\n","rf.fit(X_train, y_train)\n","\n","# Predictions on validation data\n","pred_rf = rf.predict(X_val)\n","\n","# Calculate accuracy\n","accuracy_rf = accuracy_score(y_val, pred_rf)\n","print(f\"Random Forest Classifier Accuracy: {accuracy_rf}\")\n","\n","# Train the Logistic Regression Classifier\n","# Even with 300 iterations there was a warning that the limit was reached\n","logistic = LogisticRegression(random_state=42, solver='saga', penalty='l2',\n","                              max_iter=300)\n","logistic.fit(X_train, y_train)\n","\n","# Predictions on validation data\n","pred_logistic = logistic.predict(X_val)\n","\n","# Calculate accuracy\n","accuracy_logistic = accuracy_score(y_val, pred_logistic)\n","print(f\"Logistic Regression Classifier Accuracy: {accuracy_logistic}\")\n","\n","# Train the k Nearest Neighbors Classifier\n","knn = KNeighborsClassifier(n_neighbors=3)\n","knn.fit(X_train, y_train)\n","\n","# Predictions on validation data\n","pred_knn = knn.predict(X_val)\n","\n","# Calculate accuracy\n","accuracy_knn = accuracy_score(y_val, pred_knn)\n","print(f\"k-NN Classifier Accuracy: {accuracy_knn}\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}